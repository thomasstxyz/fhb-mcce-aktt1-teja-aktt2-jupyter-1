{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0f3414",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install sklearn\n",
    "\n",
    "# Importing libraries\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Datasets\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a6588",
   "metadata": {},
   "source": [
    "### Use make_classification to create a dataset\n",
    "make_classification = Generate a random n-class classification problem.\n",
    "\n",
    "Documentation = https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification problem\n",
    "X, y = make_classification(n_samples = 1000, n_features = 20, n_informative = 5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and holdout datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87408432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision tree\n",
    "dt = DecisionTreeClassifier(random_state = 1)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe93023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Decision tree\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = plot_tree(dt,filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a04752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Decision tree on training dataset\n",
    "y_train_pred = dt.predict(X_train)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "\n",
    "# Evaluating the Decision tree on holdout or test dataset\n",
    "y_test_pred = dt.predict(X_test)\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efddaf7e",
   "metadata": {},
   "source": [
    "Since the accurcy on training data is 1.0 (= 100%), it is overfitting. So, it will not perform as well on the holdout dataset. \n",
    "Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f6e67",
   "metadata": {},
   "source": [
    "### Limit the depth of the tree\n",
    "Using the **hyperparameter** `max_depth` to limit how deep the tree grows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9589331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision tree\n",
    "dt = DecisionTreeClassifier(max_depth = 5, random_state = 1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate a Decision tree\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ee3ac",
   "metadata": {},
   "source": [
    "### Limit the number of splits of the tree\n",
    "Using the **hyperparameter** `min_samples_split` - minimum number of samples required to split an internal node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a78308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision tree\n",
    "dt = DecisionTreeClassifier(min_samples_split = 10, random_state = 1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate a Decision tree\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b4dac",
   "metadata": {},
   "source": [
    "### Limiting complexity of the tree\n",
    "\n",
    "*   **ccp_alpha**: non-negative float, default=0.0: Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See [Minimal Cost-Complexity Pruning](https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182740d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision tree\n",
    "dt = DecisionTreeClassifier(ccp_alpha=0.01, random_state = 1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate a Decision tree\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d00e30",
   "metadata": {},
   "source": [
    "Of course, the hyperparameters can be combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c645a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision tree\n",
    "dt = DecisionTreeClassifier(ccp_alpha=0.01, min_samples_split = 20, max_depth = 5, random_state = 1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate a Decision tree\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178506ff",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use the data created in the cell below. Split it into training and test data. Fit it to a decision tree with and without hyperparameter tuning. Print the results showing the performance of the tree on the training data and on the test data data with and without hyperparameter tuning.\n",
    "\n",
    "Show accuracy scores with 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification problem\n",
    "X_dt, y_dt = make_classification(n_samples = 2000, n_features = 30, n_informative = 7, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a792c99",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Ensemble of individual decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee734528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification problem\n",
    "X, y = make_classification(n_samples = 1000, n_features = 20, n_informative = 5, random_state = 1)\n",
    "\n",
    "# Split into training and holdout\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit random forest\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate random forest\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e61950",
   "metadata": {},
   "source": [
    "So, the model is overfitting. This is usual in decision trees. So, we need to use hyperparameters to prune the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db0ff3",
   "metadata": {},
   "source": [
    "### Hyperparameters of the base learner (tree)\n",
    "The first set of hyperparameters is used to control the tree structure - the base learner. Some of the key hyperparameters:\n",
    "\n",
    "*   *max_depth*: int, default=None\n",
    "*   *min_samples_split*: int or float, default=2\n",
    "*   *ccp_alpha*: non-negative float, default=0.0\n",
    "\n",
    "### Hyperparameters of the ensemble\n",
    "*   *n_estimators*: int, default=100. This hyperparameter controls how many __trees__ are part of our random forest.   \n",
    "*   *max_features*: {“sqrt”, “log2”, None}, int or float, default=”sqrt”. This hyperparameter allows us to select, what amount, or what random proportion from original __features__ are provided to an underlying decision tree.\n",
    "*   *max_samples*: int or float, default=None. This hyperparameter allows us to select, what amount, or what random proportion from original __observations__ are provided to an underlying decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid\n",
    "default_rf_grid = {# Base learner\n",
    "                   'max_depth': [2, 3, 4, 5],\n",
    "                   'min_samples_split': [2, 5, 10],\n",
    "                   'ccp_alpha': [0.0, 0.0001, 0.001, 0.01],\n",
    "                   # Ensemble\n",
    "                   'n_estimators': [100],\n",
    "                   'max_features': [\"log2\", \"sqrt\"],\n",
    "                   'max_samples': [0.5, 0.7, 0.9]\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce965a5",
   "metadata": {},
   "source": [
    "To try out all the possible combinations of the hyperparameters, we would use `GridSearchCV`. However, since the number of combinations grows very fast and therefore takes longer to calculate, we generally use `RandomizedSearchCV`. This performs a randomized search on hyperparameters. In contrast to `GridSearchCV`, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by `n_iter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Randomized search\n",
    "rf_to_tune = RandomForestClassifier()\n",
    "clf = RandomizedSearchCV(rf_to_tune, default_rf_grid, n_iter = 10, random_state = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae832709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate random forest\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2022bc9",
   "metadata": {},
   "source": [
    "Trying out more number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Randomized search\n",
    "rf_to_tune = RandomForestClassifier()\n",
    "clf = RandomizedSearchCV(rf_to_tune, default_rf_grid, cv = 3, n_iter = 50, random_state = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate random forest\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6e0aa",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use the data created in the cell below. Split it into training and test data. Fit it to a random forest with and without hyperparameter tuning. \n",
    "\n",
    "Print the results showing the performance of the model on the training data and on the test data data with and without hyperparameter tuning.\n",
    "\n",
    "Show accuracy scores with 3 decimal places.\n",
    "\n",
    "How long did it take to train the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc661525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification problem\n",
    "X_rf, y_rf = make_classification(n_samples = 1000, n_features = 20, n_informative = 5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7dc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a5c37",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Let us create a dataset for linear regression.\n",
    "\n",
    "Let us also insert a few outliers in it for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.make_regression(n_samples = 100, \n",
    "                                n_features = 1, \n",
    "                                n_informative = 1,\n",
    "                                bias = 42,\n",
    "                                noise=5,\n",
    "                                random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "# Adding outliers for demonstration purpose\n",
    "X_outlier = pd.DataFrame([-3, -2.9, 1.9, 2])\n",
    "y_outlier = pd.DataFrame([125, 125, -75, -75])\n",
    "\n",
    "y = pd.concat([y, y_outlier], ignore_index=True)\n",
    "X = pd.concat([X, X_outlier], ignore_index=True)\n",
    "\n",
    "# Note: We are not splitting the data into test and train here, just for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f36d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# instantiate the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ba476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the score of the model on our training data\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee7c4e",
   "metadata": {},
   "source": [
    "Here the baseline model would be a simple average of all the values.\n",
    "\n",
    "1 would be a perfect score and 0 would be the score of the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prections for all observations in the training dataset using the trained model\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cec455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# run this cell to visualize original data together with predictions\n",
    "plt.scatter(X, y, label='data')\n",
    "plt.scatter(X, y_pred, label='predictions')\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf272c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the errors between the predicted and actual values\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "\n",
    "print(f'Mean absolute error: {mae}')\n",
    "print(f'Mean squared error: {mse}')\n",
    "print(f'Root mean squared error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a08b20",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use the data created in the cell below. Split it into training and test data. Fit it to a linear regression model. Plot the input data and predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf97a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg, y_reg = datasets.make_regression(n_samples = 1000, \n",
    "                                n_features = 1, \n",
    "                                n_informative = 1,\n",
    "                                bias = 42,\n",
    "                                noise=5,\n",
    "                                random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8680a",
   "metadata": {},
   "source": [
    "# k-Nearest-Neighbors (kNN) Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a2d99",
   "metadata": {},
   "source": [
    "We will work with one of the datasets available in sklearn - breast cancer. This dataset contains 30 numeric features and 1 binary target feature (malignant or benign) and is hence an ideal candidate for kNN algorithm. Details [here](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9726dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a sample dataset from sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer[\"data\"]\n",
    "y = breast_cancer[\"target\"]\n",
    "\n",
    "print(\"Dimensions of independent features: \" + str(X.shape))\n",
    "print(\"Dimensions of target feature: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target feature\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718910aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Instantiate\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform (rewrite original dfs)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f988918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Instantiate\n",
    "kNN_simplest = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "# Fit\n",
    "kNN_simplest.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = kNN_simplest.predict(X_train)\n",
    "y_test_pred = kNN_simplest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ea33c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"Accuracy on training data: \" + str(round(accuracy_score(y_train, y_train_pred), 2)))\n",
    "print(\"Accuracy on holdout data: \" + str(round(accuracy_score(y_test, y_test_pred), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef111da",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use the breast cancer data. Use `GridSearchCV` to tune the kNN hyperparameters: `n_neighbors` and `algorithm`. Use the [scikit-learn](https://scikit-learn.org/) documentation to find the relevant parameter values.\n",
    "\n",
    "Print the accuracy on the training and holdout data after tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# Solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
