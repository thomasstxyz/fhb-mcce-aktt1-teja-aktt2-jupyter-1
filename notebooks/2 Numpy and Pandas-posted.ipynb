{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d94494",
   "metadata": {},
   "source": [
    "## Working with numerical data\n",
    "\n",
    "The \"data\" in *Data Analysis* typically refers to numerical data, e.g., stock prices, sales figures, sensor measurements, sports scores, database tables, etc. The [Numpy](https://numpy.org) library provides specialized data structures, functions, and other tools for numerical computing in Python. Let's work through an example to see why & how to use Numpy for working with numerical data.\n",
    "\n",
    "\n",
    "> Suppose we want to use climate data like the temperature, rainfall, and humidity to determine if a region is well suited for growing apples. A simple approach for doing this would be to formulate the relationship between the annual yield of apples (tons per hectare) and the climatic conditions like the average temperature (in degrees Fahrenheit), rainfall (in  millimeters) & average relative humidity (in percentage) as a linear equation.\n",
    ">\n",
    "> `yield_of_apples = w1 * temperature + w2 * rainfall + w3 * humidity`\n",
    "\n",
    "We're expressing the yield of apples as a __weighted__ sum of the temperature, rainfall, and humidity. This equation is an approximation since the actual relationship may not necessarily be linear, and there may be other factors involved. But a simple linear model like this often works well in practice.\n",
    "\n",
    "Based on some statical analysis of historical data, we might come up with reasonable values for the weights `w1`, `w2`, and `w3`. Here's an example set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3 = 0.3, 0.2, 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad15cb",
   "metadata": {},
   "source": [
    "Given some climate data for a region, we can now predict the yield of apples. Here's some sample data:\n",
    "\n",
    "<img src=\"https://i.imgur.com/TXPBiqv.png\" style=\"width:360px;\">\n",
    "\n",
    "To begin, we can define some variables to record climate data for a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "kanto_temp = 73\n",
    "kanto_rainfall = 67\n",
    "kanto_humidity = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67be437",
   "metadata": {},
   "outputs": [],
   "source": [
    "kanto_yield_apples = kanto_temp * w1 + kanto_rainfall * w2 + kanto_humidity * w3\n",
    "kanto_yield_apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac916bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kanto = [73, 67, 43]\n",
    "johto = [91, 88, 64]\n",
    "hoenn = [87, 134, 58]\n",
    "sinnoh = [102, 43, 37]\n",
    "unova = [69, 96, 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [w1, w2, w3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13119ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_yield(region, weights):\n",
    "    result = 0\n",
    "    for x, w in zip(region, weights):\n",
    "        result += x * w\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_yield(kanto, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_yield(johto, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4377112",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_yield(unova, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7737582",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0418a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kanto = np.array([73, 67, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f96fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([w1, w2, w3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ccb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(kanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabf29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kanto[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(kanto, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bac6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = np.array([[73, 67, 43],\n",
    "                         [91, 88, 64],\n",
    "                         [87, 134, 58],\n",
    "                         [102, 43, 37],\n",
    "                         [69, 96, 70]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbdf1d",
   "metadata": {},
   "source": [
    "You may recognize the above 2-d array as a matrix with five rows and three columns. Each row represents one region, and the columns represent temperature, rainfall, and humidity, respectively.\n",
    "\n",
    "Numpy arrays can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of an array.\n",
    "\n",
    "<img src=\"https://fgnt.github.io/python_crashkurs_doc/_images/numpy_array_t.png\" width=\"420\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc209590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D array (matrix)\n",
    "climate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f964c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"climate.csv\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    content = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b88f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4070b2",
   "metadata": {},
   "source": [
    "## Operating on Numpy arrays\n",
    "\n",
    "We can now compute the dot product of the two vectors using the `np.dot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6397f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(kanto, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "(kanto * weights).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9dd536",
   "metadata": {},
   "source": [
    "The `*` operator performs an element-wise multiplication of two arrays if they have the same size. The `sum` method calculates the sum of numbers in an array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9be4ea",
   "metadata": {},
   "source": [
    "We can now compute the predicted yields of apples in all the regions, using a single matrix multiplication between `climate_data` (a 5x3 matrix) and `weights` (a vector of length 3). Here's what it looks like visually:\n",
    "\n",
    "<img src=\"https://i.imgur.com/LJ2WKSI.png\" width=\"240\">\n",
    "\n",
    "We can use the `np.matmul` function or the `@` operator to perform matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47acc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(climate_data, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66251694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    'https://gist.github.com/BirajCoder/a4ffcb76fd6fb221d76ac2ee2b8584e9/raw/4054f90adfd361b7aa4255e99c2e874664094cea/climate.csv', \n",
    "    'climate.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246926e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data = np.genfromtxt('climate.txt', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.3, 0.2, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6662d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yields = climate_data @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef48a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ae2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f260b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "yields.reshape(10000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955de370",
   "metadata": {},
   "outputs": [],
   "source": [
    "yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eac459",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_results = np.concatenate((climate_data, yields.reshape(10000,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d22d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('climate_results.txt', \n",
    "           climate_results, \n",
    "           fmt='%.2f', \n",
    "           delimiter=',',\n",
    "           header='temperature,rainfall,humidity,yield_apples',\n",
    "           comments = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7e777",
   "metadata": {},
   "source": [
    "## Arithmetic operations, broadcasting and comparison\n",
    "\n",
    "Numpy arrays support arithmetic operators like `+`, `-`, `*`, etc. You can perform an arithmetic operation with a single number (also called scalar) or with another array of the same shape. Operators make it easy to write mathematical expressions with multi-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c46944",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([[1, 2, 3, 4], \n",
    "                 [5, 6, 7, 8], \n",
    "                 [9, 1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0efbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3 = np.array([[11, 12, 13, 14], \n",
    "                 [15, 16, 17, 18], \n",
    "                 [19, 11, 12, 13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a scalar\n",
    "arr2 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b419c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise subtraction\n",
    "arr3 - arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division by scalar\n",
    "arr2 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise multiplication\n",
    "arr2 * arr3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e3d2f",
   "metadata": {},
   "source": [
    "### Array Broadcasting\n",
    "\n",
    "Numpy arrays also support *broadcasting*, allowing arithmetic operations between two arrays with different numbers of dimensions but compatible shapes. Let's look at an example to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([[1, 2, 3, 4], \n",
    "                 [5, 6, 7, 8], \n",
    "                 [9, 1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr4 = np.array([4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 + arr4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8d6fa",
   "metadata": {},
   "source": [
    "When the expression `arr2 + arr4` is evaluated, `arr4` (which has the shape `(4,)`) is replicated three times to match the shape `(3, 4)` of `arr2`. Numpy performs the replication without actually creating three copies of the smaller dimension array, thus improving performance and using lower memory.\n",
    "\n",
    "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/02.05-broadcasting.png\" width=\"360\">\n",
    "\n",
    "Broadcasting only works if one of the arrays can be replicated to match the other array's shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69a036",
   "metadata": {},
   "source": [
    "## Array indexing and slicing\n",
    "\n",
    "Numpy extends Python's list indexing notation using `[]` to multiple dimensions in an intuitive fashion. You can provide a comma-separated list of indices or ranges to select a specific element or a subarray (also called a slice) from a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea759a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3 = np.array([\n",
    "    [[11, 12, 13, 14], \n",
    "     [13, 14, 15, 19]], \n",
    "    \n",
    "    [[15, 16, 17, 21], \n",
    "     [63, 92, 36, 18]], \n",
    "    \n",
    "    [[98, 32, 81, 23],      \n",
    "     [17, 18, 19.5, 43]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa314b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b4c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single element\n",
    "arr3[1, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a803974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subarray using ranges\n",
    "arr3[1:, 0:1, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1188ae86",
   "metadata": {},
   "source": [
    "### Exercise 1: \n",
    "Sort the array:\n",
    "[[10 40]\n",
    " [30 20]]\n",
    "1. Along the first axis\n",
    "2. Along the second axis\n",
    "3. As a flattened array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e596624",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "Write a NumPy program to create a structured array from given student name, class, height and their data types. Now sort by class, then height if class are equal.\n",
    "\n",
    "[('James', 5, 178), ('Neil', 6, 180),('Paul', 5, 176), ('Sam', 5, 175)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2faeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0774e1",
   "metadata": {},
   "source": [
    "# Analyzing Tabular Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df7da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21726792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('italy-covid-daywise.csv', <http.client.HTTPMessage at 0x29533641940>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "italy_covid_url = 'https://gist.githubusercontent.com/aakashns/f6a004fa20c84fec53262f9a8bfee775/raw/f309558b1cf5103424cef58e2ecb8704dcd4d74c/italy-covid-daywise.csv'\n",
    "\n",
    "urlretrieve(italy_covid_url, 'italy-covid-daywise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795cfdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99f446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = pd.read_csv('italy-covid-daywise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ef50a",
   "metadata": {},
   "source": [
    "Data from the file is read and stored in a `DataFrame` object - one of the core data structures in Pandas for storing and working with tabular data. We typically use the `_df` suffix in the variable names for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c02982",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ebbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8909844",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fdfbb",
   "metadata": {},
   "source": [
    "## Retrieving data from a data frame\n",
    "\n",
    "The first thing you might want to do is retrieve data from this data frame, e.g., the counts of a specific day or the list of values in a particular column. To do this, it might help to understand the internal representation of data in a data frame. Conceptually, you can think of a dataframe as a dictionary of lists: keys are column names, and values are lists/arrays containing data for the respective columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas format is simliar to this\n",
    "covid_data_dict = {\n",
    "    'date':       ['2020-08-30', '2020-08-31', '2020-09-01', '2020-09-02', '2020-09-03'],\n",
    "    'new_cases':  [1444, 1365, 996, 975, 1326],\n",
    "    'new_deaths': [1, 4, 6, 8, 6],\n",
    "    'new_tests': [53541, 42583, 54395, None, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb632e",
   "metadata": {},
   "source": [
    "With the dictionary of lists analogy in mind, you can now guess how to retrieve data from a data frame. For example, we can get a list of values from a specific column using the `[]` indexing notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data_dict['new_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['new_tests']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016e741",
   "metadata": {},
   "source": [
    "Each column is represented using a data structure called `Series`, which is essentially a numpy array with some extra methods and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3500970",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(covid_df['new_cases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f6c643",
   "metadata": {},
   "source": [
    "Like arrays, you can retrieve a specific value with a series using the indexing notation `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['new_cases'][246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['new_tests'][240]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b5042c",
   "metadata": {},
   "source": [
    "Pandas also provides the `.at` method to retrieve the element at a specific row & column directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439dd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.at[246, 'new_cases']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbb00f",
   "metadata": {},
   "source": [
    "You can also pass a list of columns within the indexing notation `[]` to access a subset of the data frame with just the given columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_df = covid_df[['date', 'new_cases']]\n",
    "cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa9a25",
   "metadata": {},
   "source": [
    "The new data frame `cases_df` is simply a \"view\" of the original data frame `covid_df`. Both point to the same data in the computer's memory. Changing any values inside one of them will also change the respective values in the other. Sharing data between data frames makes data manipulation in Pandas blazing fast. You needn't worry about the overhead of copying thousands or millions of rows every time you want to create a new data frame by operating on an existing one.\n",
    "\n",
    "Sometimes you might need a full copy of the data frame, in which case you can use the `copy` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df_copy = covid_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69003a01",
   "metadata": {},
   "source": [
    "The data within `covid_df_copy` is completely separate from `covid_df`, and changing values inside one of them will not affect the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[246]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7508030",
   "metadata": {},
   "source": [
    "Each retrieved row is also a `Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(covid_df.loc[243])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae46a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.new_tests.first_valid_index() # That does not contain NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbf49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[108:113]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05adfe",
   "metadata": {},
   "source": [
    "## Analyzing data from data frames\n",
    "\n",
    "Let's try to answer some questions about our data.\n",
    "\n",
    "**Q: What are the total number of reported cases and deaths related to Covid-19 in Italy?**\n",
    "\n",
    "Similar to Numpy arrays, a Pandas series supports the `sum` method to answer these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e70413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases = covid_df.new_cases.sum()\n",
    "total_deaths = covid_df.new_deaths.sum()\n",
    "print('The number of reported cases is {} and the number of reported deaths is {}.'.format((total_cases), (total_deaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of reported cases is {} and the number of reported deaths is {}.'.format(int(total_cases), int(total_deaths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0fc3a4",
   "metadata": {},
   "source": [
    "**Q: What is the overall death rate (ratio of reported deaths to reported cases)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f915362",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate = covid_df.new_deaths.sum() / covid_df.new_cases.sum()\n",
    "print(\"The overall reported death rate in Italy is {:.2f} %.\".format(death_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85685d41",
   "metadata": {},
   "source": [
    "**Q: What is the overall number of tests conducted? A total of 935310 tests were conducted before daily test numbers were reported.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tests = 935310\n",
    "total_tests = initial_tests + covid_df.new_tests.sum()\n",
    "print(int(total_tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4993c",
   "metadata": {},
   "source": [
    "**Q: What fraction of tests returned a positive result?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate = total_cases / total_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33668c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.2f}% of tests in Italy led to a positive diagnosis.'.format(positive_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e53f6e",
   "metadata": {},
   "source": [
    "## Querying and sorting rows\n",
    "\n",
    "Let's say we want only want to look at the days which had more than 5000 reported cases. We can use a boolean expression to check which rows satisfy this criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516169c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_new_cases = covid_df.new_cases > 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a38cae",
   "metadata": {},
   "source": [
    "The boolean expression returns a series containing `True` and `False` boolean values. You can use this series to select a subset of rows from the original dataframe, corresponding to the `True` values in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e613b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df[high_new_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf0cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[169:175]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9191e5",
   "metadata": {},
   "source": [
    "We can also formulate more complex queries that involve multiple columns. As an example, let's try to determine the days when the ratio of cases reported to tests conducted is higher than the overall `positive_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ratio_df = covid_df[covid_df.new_cases / covid_df.new_tests > positive_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148eab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_ratio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084510a",
   "metadata": {},
   "source": [
    "The result of performing an operation on two columns is a new series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42941140",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['positive_rate'] = covid_df.new_cases / covid_df.new_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.drop(columns=['positive_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fa450",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.drop(columns=['positive_rate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdb63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74555d",
   "metadata": {},
   "source": [
    "### Sorting rows using column values\n",
    "\n",
    "The rows can also be sorted by a specific column using `.sort_values`. Let's sort to identify the days with the highest number of cases, then chain it with the `head` method to list just the first ten results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_cases', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edda63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_cases', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985496d",
   "metadata": {},
   "source": [
    "It looks like the last two weeks of March had the highest number of daily cases. Let's compare this to the days where the highest number of deaths were recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f80a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_deaths', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabbe8f7",
   "metadata": {},
   "source": [
    "It appears that daily deaths hit a peak just about a week after the peak in daily new cases.\n",
    "\n",
    "Let's also look at the days with the least number of cases. We might expect to see the first few days of the year on this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c83d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_cases').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637d4cd",
   "metadata": {},
   "source": [
    "It seems like the count of new cases on Jun 20, 2020, was `-148`, a negative number! Not something we might have expected, but that's the nature of real-world data. It could be a data entry error, or the government may have issued a correction to account for miscounting in the past.\n",
    "\n",
    "Let's look at some days before and after Jun 20, 2020 (around location 172)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39644e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[169:175]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cbac0d",
   "metadata": {},
   "source": [
    "For now, let's assume this was indeed a data entry error. We can use one of the following approaches for dealing with the missing or faulty value:\n",
    "1. Replace it with `0`.\n",
    "2. Replace it with the average of the entire column\n",
    "3. Replace it with the average of the values on the previous & next date\n",
    "4. Discard the row entirely\n",
    "\n",
    "Which approach you pick requires some context about the data and the problem. In this case, since we are dealing with data ordered by date, we can go ahead with the third approach.\n",
    "\n",
    "You can use the `.at` method to modify a specific value within the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4260d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.at[172, 'new_cases'] = (covid_df.at[171, 'new_cases'] + covid_df.at[173, 'new_cases'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88391d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.loc[169:175]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb9698",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Here's a summary of the functions & methods we looked at in this section:\n",
    "\n",
    "- `covid_df.new_cases.sum()` - Computing the sum of values in a column or series\n",
    "- `covid_df[covid_df.new_cases > 1000]` - Querying a subset of rows satisfying the chosen criteria using boolean expressions\n",
    "- `df['pos_rate'] = df.new_cases/df.new_tests` - Adding new columns by combining data from existing columns\n",
    "- `covid_df.drop('positive_rate')` - Removing one or more columns from the data frame\n",
    "- `sort_values` - Sorting the rows of a data frame using column values\n",
    "- `covid_df.at[172, 'new_cases'] = ...` - Replacing a value within the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d4a7f",
   "metadata": {},
   "source": [
    "## Working with dates\n",
    "\n",
    "While we've looked at overall numbers for the cases, tests, positive rate, etc., it would also be useful to study these numbers on a month-by-month basis. The `date` column might come in handy here, as Pandas provides many utilities for working with dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b63f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2377dbf",
   "metadata": {},
   "source": [
    "The data type of date is currently `object`, so Pandas does not know that this column is a date. We can convert it into a `datetime` column using the `pd.to_datetime` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['date'] = pd.to_datetime(covid_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecee9ae",
   "metadata": {},
   "source": [
    "You can see that it now has the datatype `datetime64`. We can now extract different parts of the data into separate columns, using the `DatetimeIndex` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc73475",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['year'] = pd.DatetimeIndex(covid_df.date).year\n",
    "covid_df['month'] = pd.DatetimeIndex(covid_df.date).month\n",
    "covid_df['day'] = pd.DatetimeIndex(covid_df.date).day\n",
    "covid_df['weekday'] = pd.DatetimeIndex(covid_df.date).weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e212041",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e8bb4",
   "metadata": {},
   "source": [
    "Let's check the overall metrics for May. We can query the rows for May, choose a subset of columns, and use the `sum` method to aggregate each selected column's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the rows for May\n",
    "covid_df_may = covid_df[covid_df.month == 5]\n",
    "\n",
    "# Extract the subset of columns to be aggregated\n",
    "covid_df_may_metrics = covid_df_may[['new_cases', 'new_deaths', 'new_tests']]\n",
    "\n",
    "# Get the column-wise sum\n",
    "covid_may_totals = covid_df_may_metrics.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_may_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19129865",
   "metadata": {},
   "source": [
    "As another example, let's check if the number of cases reported on Sundays is higher than the average number of cases reported every day. This time, we might want to aggregate columns using the `.mean` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df151a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall average\n",
    "covid_df.new_cases.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5248155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average for Sundays\n",
    "covid_df[covid_df.weekday == 6].new_cases.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ab94f",
   "metadata": {},
   "source": [
    "## Grouping and aggregation\n",
    "\n",
    "As a next step, we might want to summarize the day-wise data and create a new dataframe with month-wise data. We can use the `groupby` function to create a group for each month, select the columns we wish to aggregate, and aggregate them using the `sum` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22bd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df = covid_df.groupby('month')[['new_cases', 'new_deaths', 'new_tests']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce075ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353456e2",
   "metadata": {},
   "source": [
    "The result is a new data frame that uses unique values from the column passed to `groupby` as the index. Grouping and aggregation is a powerful method for progressively summarizing data into smaller data frames.\n",
    "\n",
    "Instead of aggregating by sum, you can also aggregate by other measures like mean. Let's compute the average number of daily new cases, deaths, and tests for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62416aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_mean_df = covid_df.groupby('month')[['new_cases', 'new_deaths', 'new_tests']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b86e7",
   "metadata": {},
   "source": [
    "Apart from grouping, another form of aggregation is the running or cumulative sum of cases, tests, or death up to each row's date. We can use the `cumsum` method to compute the cumulative sum of a column as a new series. Let's add three new columns: `total_cases`, `total_deaths`, and `total_tests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6f453",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['total_cases'] = covid_df.new_cases.cumsum()\n",
    "covid_df['total_deaths'] = covid_df.new_deaths.cumsum()\n",
    "covid_df['total_tests'] = covid_df.new_tests.cumsum() + initial_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ddbaa",
   "metadata": {},
   "source": [
    "## Merging data from multiple sources\n",
    "\n",
    "To determine other metrics like test per million, cases per million, etc., we require some more information about the country, viz. its population. Let's download another file `locations.csv` that contains health-related information for many countries, including Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfefcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlretrieve('https://gist.githubusercontent.com/aakashns/8684589ef4f266116cdce023377fc9c8/raw/99ce3826b2a9d1e6d0bde7e9e559fc8b6e9ac88b/locations.csv', \n",
    "            'locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.read_csv('locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df[locations_df['location'] == 'Ukraine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df[locations_df['location'] == 'Italy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34a8b1",
   "metadata": {},
   "source": [
    "We can merge this data into our existing data frame by adding more columns. However, to merge two data frames, we need at least one common column. Let's insert a `location` column in the `covid_df` dataframe with all values set to `\"Italy\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7dd062",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['location'] = \"Italy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029d4e6",
   "metadata": {},
   "source": [
    "We can now add the columns from `locations_df` into `covid_df` using the `.merge` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90de7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = covid_df.merge(locations_df, on=\"location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a7e20",
   "metadata": {},
   "source": [
    "The location data for Italy is appended to each row within `covid_df`. If the `covid_df` data frame contained data for multiple locations, then the respective country's location data would be appended for each row.\n",
    "\n",
    "We can now calculate metrics like cases per million, deaths per million, and tests per million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['cases_per_million'] = merged_df.total_cases * 1e6 / merged_df.population\n",
    "merged_df['deaths_per_million'] = merged_df.total_deaths * 1e6 / merged_df.population\n",
    "merged_df['tests_per_million'] = merged_df.total_tests * 1e6 / merged_df.population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3379776",
   "metadata": {},
   "source": [
    "## Writing data back to files\n",
    "\n",
    "After completing your analysis and adding new columns, you should write the results back to a file. Otherwise, the data will be lost when the Jupyter notebook shuts down. Before writing to file, let us first create a data frame containing just the columns we wish to record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = merged_df[['date',\n",
    "                       'new_cases', \n",
    "                       'total_cases', \n",
    "                       'new_deaths', \n",
    "                       'total_deaths', \n",
    "                       'new_tests', \n",
    "                       'total_tests', \n",
    "                       'cases_per_million', \n",
    "                       'deaths_per_million', \n",
    "                       'tests_per_million']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295936a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04464bad",
   "metadata": {},
   "source": [
    "To write the data from the data frame into a file, we can use the `to_csv` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('results.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed752bd3",
   "metadata": {},
   "source": [
    "The `to_csv` function also includes an additional column for storing the index of the dataframe by default. We pass `index=None` to turn off this behavior. You can now verify that the `results.csv` is created and contains data from the data frame in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a50f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv('results.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80e314",
   "metadata": {},
   "source": [
    "# Basic Plotting with Pandas\n",
    "\n",
    "We generally use a library like `matplotlib` or `seaborn` plot graphs within a Jupyter notebook. However, Pandas dataframes & series provide a handy `.plot` method for quick and easy plotting.\n",
    "\n",
    "Let's plot a line graph showing how the number of daily cases varies over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.new_cases.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cd2a8",
   "metadata": {},
   "source": [
    "While this plot shows the overall trend, it's hard to tell where the peak occurred, as there are no dates on the X-axis. We can use the `date` column as the index for the data frame to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feda0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2f128",
   "metadata": {},
   "source": [
    "Notice that the index of a data frame doesn't have to be numeric. Using the date as the index also allows us to get the data for a specific data using `.loc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.loc['2020-09-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.new_cases.plot()\n",
    "result_df.new_deaths.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055a954",
   "metadata": {},
   "source": [
    "We can also compare the total cases vs. total deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.total_cases.plot()\n",
    "result_df.total_deaths.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64436f6c",
   "metadata": {},
   "source": [
    "Let's see how the death rate and positive testing rates vary over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31999c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate = result_df.total_deaths / result_df.total_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a42070",
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rate.plot(title='Death Rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73953624",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_rates = result_df.total_cases / result_df.total_tests\n",
    "positive_rates.plot(title='Positive Rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9cf9af",
   "metadata": {},
   "source": [
    "Finally, let's plot some month-wise data using a bar chart to visualize the trend at a higher level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df.new_cases.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011454e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df.new_tests.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_month_df.new_tests.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1fa50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
